{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1d41306",
    "outputId": "69daa029-19be-4fe8-bcd8-ea25dcb5796d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\madhu\\anaconda3\\lib\\site-packages (1.45.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\madhu\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (2.1.3)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (4.0.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
      "Requirement already satisfied: joblib in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\madhu\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install streamlit nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9fb6ea5",
    "outputId": "698afa01-5d14-4373-a707-d5246d9fbc08"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 13:32:09.640 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:32:09.872 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\madhu\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-07-23 13:32:09.873 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:32:09.873 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:32:09.874 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:32:09.874 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:32:09.875 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:32:09.875 Session state does not function when running a script without `streamlit run`\n",
      "2025-07-23 13:32:09.875 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:32:09.876 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:32:09.877 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:32:09.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:32:09.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:32:09.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:32:09.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "     nltk.download('stopwords')\n",
    "\n",
    "try:\n",
    "    with open('model.pkl', 'rb') as model_file:\n",
    "        model = pickle.load(model_file)\n",
    "    with open('vectorizer.pkl', 'rb') as vectorizer_file:\n",
    "        vectorizer = pickle.load(vectorizer_file)\n",
    "except FileNotFoundError:\n",
    "    st.error(\"Error: model.pkl or vectorizer.pkl not found. Please make sure the files are in the same directory.\")\n",
    "    st.stop() \n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses the input text: removes non-alphabetic characters,\n",
    "    converts to lowercase, tokenizes, removes stopwords, and applies stemming.\n",
    "    \"\"\"\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = [ps.stem(word) for word in text if not word in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "st.title(\"Fake News Detector\") \n",
    "\n",
    "news_text = st.text_area(\"Enter the news text here:\")\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "\n",
    "    if news_text:\n",
    "        \n",
    "        preprocessed_text = preprocess_text(news_text)\n",
    "\n",
    "        vectorized_text = vectorizer.transform([preprocessed_text])\n",
    "\n",
    "        prediction = model.predict(vectorized_text)\n",
    "\n",
    "        if prediction[0] == 0:\n",
    "            st.error(\"Result: This appears to be FAKE News.\")\n",
    "        else:\n",
    "            st.success(\"Result: This appears to be REAL News.\")\n",
    "    else:\n",
    "        st.warning(\"Please enter some text to analyze.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10155f62",
    "outputId": "258cf581-b90b-46f5-be9c-7764198f9937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script saved successfully to E:/carr/btech cse/Semester 5/cohort summer school/fake news project/Fake_news_detector_app.py\n"
     ]
    }
   ],
   "source": [
    "# Content of the Fake_news_detector_app.py script\n",
    "script_content = \"\"\"\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "     nltk.download('stopwords')\n",
    "\n",
    "try:\n",
    "    with open('model.pkl', 'rb') as model_file:\n",
    "        model = pickle.load(model_file)\n",
    "    with open('vectorizer.pkl', 'rb') as vectorizer_file:\n",
    "        vectorizer = pickle.load(vectorizer_file)\n",
    "except FileNotFoundError:\n",
    "    st.error(\"Error: model.pkl or vectorizer.pkl not found. Please make sure the files are in the same directory.\")\n",
    "    st.stop() \n",
    "\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \\\"\\\"\\\"\n",
    "    Preprocesses the input text: removes non-alphabetic characters,\n",
    "    converts to lowercase, tokenizes, removes stopwords, and applies stemming.\n",
    "    \\\"\\\"\\\"\n",
    "\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "   \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = text.split()\n",
    "   \n",
    "    text = [ps.stem(word) for word in text if not word in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "st.title(\"Fake News Detector\") # Set the title of the application\n",
    "\n",
    "\n",
    "news_text = st.text_area(\"Enter the news text here:\")\n",
    "\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "    \n",
    "    if news_text:\n",
    "        \n",
    "        preprocessed_text = preprocess_text(news_text)\n",
    "\n",
    "        \n",
    "        vectorized_text = vectorizer.transform([preprocessed_text])\n",
    "\n",
    "        \n",
    "        prediction = model.predict(vectorized_text)\n",
    "\n",
    "        \n",
    "        if prediction[0] == 0:\n",
    "           \n",
    "            st.error(\"Result: This appears to be FAKE News.\")\n",
    "        else:\n",
    "            \n",
    "            st.success(\"Result: This appears to be REAL News.\")\n",
    "    else:\n",
    "        \n",
    "        st.warning(\"Please enter some text to analyze.\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "file_path = 'E:/carr/btech cse/Semester 5/cohort summer school/fake news project/Fake_news_detector_app.py'\n",
    "\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write(script_content)\n",
    "\n",
    "print(f\"Script saved successfully to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Now push the pkl files and Fake_news_detector_app.py of this project  to the same git hub directory and deploy the app using streamlit cloud."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
